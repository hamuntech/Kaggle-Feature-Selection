{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   Unnamed: 0          ID                                               name  \\\n0           0  1000002330                    The Songs of Adelaide & Abullah   \n1           1  1000003930      Greeting From Earth: ZGAC Arts Capsule For ET   \n2           2  1000004038                                     Where is Hank?   \n3           3  1000007540  ToshiCapital Rekordz Needs Help to Complete Album   \n4           4  1000011046  Community Film Project: The Art of Neighborhoo...   \n5           5  1000014025                               Monarch Espresso Bar   \n6           6  1000023410  Support Solar Roasted Coffee & Green Energy!  ...   \n7           7  1000030581  Chaser Strips. Our Strips make Shots their B*tch!   \n8           8  1000034518  SPIN - Premium Retractable In-Ear Headphones w...   \n9           9   100004195  STUDIO IN THE SKY - A Documentary Feature Film...   \n\n         category main_category currency   deadline      goal  \\\n0          Poetry    Publishing      GBP 2015-10-09    1000.0   \n1  Narrative Film  Film & Video      USD 2017-11-01   30000.0   \n2  Narrative Film  Film & Video      USD 2013-02-26   45000.0   \n3           Music         Music      USD 2012-04-16    5000.0   \n4    Film & Video  Film & Video      USD 2015-08-29   19500.0   \n5     Restaurants          Food      USD 2016-04-01   50000.0   \n6            Food          Food      USD 2014-12-21    1000.0   \n7          Drinks          Food      USD 2016-03-17   25000.0   \n8  Product Design        Design      USD 2014-05-29  125000.0   \n9     Documentary  Film & Video      USD 2014-08-10   65000.0   \n\n             launched   pledged  ... n_polysyllable_words  \\\n0 2015-08-11 12:12:28      0.00  ...                    1   \n1 2017-09-02 04:43:57   2421.00  ...                    0   \n2 2013-01-12 00:20:50    220.00  ...                    0   \n3 2012-03-17 03:24:11      1.00  ...                    1   \n4 2015-07-04 08:35:03   1283.00  ...                    3   \n5 2016-02-26 13:38:27  52375.00  ...                    0   \n6 2014-12-01 18:30:44   1205.00  ...                    2   \n7 2016-02-01 20:05:12    453.00  ...                    0   \n8 2014-04-24 18:14:43   8233.00  ...                    1   \n9 2014-07-11 21:55:48   6240.57  ...                    1   \n\n   flesch_kincaid_grade_level flesch_reading_ease  smog_index  \\\n0                    5.240000           66.400000    8.841846   \n1                    0.720000           97.025000    3.129100   \n2                   -2.620000          119.190000    3.129100   \n3                   10.740000           30.530000    8.841846   \n4                    9.655000           40.090000   13.023867   \n5                    1.313333           90.990000    3.129100   \n6                   14.432143           -2.174643    8.841846   \n7                   -0.755000          107.600000    3.129100   \n8                    3.670000           75.875000    7.168622   \n9                    7.586667           56.700000    8.841846   \n\n   gunning_fog_index  coleman_liau_index  automated_readability_index  \\\n0          10.000000            7.680995                     4.620000   \n1           1.600000            3.996687                     2.353750   \n2           1.200000           -4.103777                    -2.660000   \n3           8.514286           16.091526                    11.002857   \n4          18.200000           17.249855                    12.007500   \n5           1.200000            9.615875                     8.330000   \n6          12.828571           17.744623                    13.962857   \n7           1.600000            6.201631                     4.120000   \n8           6.600000            9.141557                     6.475000   \n9           8.044444           10.310975                     6.620000   \n\n         lix  gulpease_index  wiener_sachtextformel  \n0  45.000000       99.000000               7.057000  \n1  29.000000      117.750000               0.583800  \n2   3.000000      152.333333              -3.643400  \n3  49.857143       70.428571               7.216829  \n4  58.000000       64.000000              12.160100  \n5  69.666667      129.000000               6.093267  \n6  46.357143      103.285714              10.330200  \n7   4.000000      114.000000              -3.067450  \n8  41.500000      109.000000               5.032550  \n9  42.333333       72.333333               5.286467  \n\n[10 rows x 33 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>ID</th>\n      <th>name</th>\n      <th>category</th>\n      <th>main_category</th>\n      <th>currency</th>\n      <th>deadline</th>\n      <th>goal</th>\n      <th>launched</th>\n      <th>pledged</th>\n      <th>...</th>\n      <th>n_polysyllable_words</th>\n      <th>flesch_kincaid_grade_level</th>\n      <th>flesch_reading_ease</th>\n      <th>smog_index</th>\n      <th>gunning_fog_index</th>\n      <th>coleman_liau_index</th>\n      <th>automated_readability_index</th>\n      <th>lix</th>\n      <th>gulpease_index</th>\n      <th>wiener_sachtextformel</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1000002330</td>\n      <td>The Songs of Adelaide &amp; Abullah</td>\n      <td>Poetry</td>\n      <td>Publishing</td>\n      <td>GBP</td>\n      <td>2015-10-09</td>\n      <td>1000.0</td>\n      <td>2015-08-11 12:12:28</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>1</td>\n      <td>5.240000</td>\n      <td>66.400000</td>\n      <td>8.841846</td>\n      <td>10.000000</td>\n      <td>7.680995</td>\n      <td>4.620000</td>\n      <td>45.000000</td>\n      <td>99.000000</td>\n      <td>7.057000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1000003930</td>\n      <td>Greeting From Earth: ZGAC Arts Capsule For ET</td>\n      <td>Narrative Film</td>\n      <td>Film &amp; Video</td>\n      <td>USD</td>\n      <td>2017-11-01</td>\n      <td>30000.0</td>\n      <td>2017-09-02 04:43:57</td>\n      <td>2421.00</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0.720000</td>\n      <td>97.025000</td>\n      <td>3.129100</td>\n      <td>1.600000</td>\n      <td>3.996687</td>\n      <td>2.353750</td>\n      <td>29.000000</td>\n      <td>117.750000</td>\n      <td>0.583800</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>1000004038</td>\n      <td>Where is Hank?</td>\n      <td>Narrative Film</td>\n      <td>Film &amp; Video</td>\n      <td>USD</td>\n      <td>2013-02-26</td>\n      <td>45000.0</td>\n      <td>2013-01-12 00:20:50</td>\n      <td>220.00</td>\n      <td>...</td>\n      <td>0</td>\n      <td>-2.620000</td>\n      <td>119.190000</td>\n      <td>3.129100</td>\n      <td>1.200000</td>\n      <td>-4.103777</td>\n      <td>-2.660000</td>\n      <td>3.000000</td>\n      <td>152.333333</td>\n      <td>-3.643400</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>1000007540</td>\n      <td>ToshiCapital Rekordz Needs Help to Complete Album</td>\n      <td>Music</td>\n      <td>Music</td>\n      <td>USD</td>\n      <td>2012-04-16</td>\n      <td>5000.0</td>\n      <td>2012-03-17 03:24:11</td>\n      <td>1.00</td>\n      <td>...</td>\n      <td>1</td>\n      <td>10.740000</td>\n      <td>30.530000</td>\n      <td>8.841846</td>\n      <td>8.514286</td>\n      <td>16.091526</td>\n      <td>11.002857</td>\n      <td>49.857143</td>\n      <td>70.428571</td>\n      <td>7.216829</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>1000011046</td>\n      <td>Community Film Project: The Art of Neighborhoo...</td>\n      <td>Film &amp; Video</td>\n      <td>Film &amp; Video</td>\n      <td>USD</td>\n      <td>2015-08-29</td>\n      <td>19500.0</td>\n      <td>2015-07-04 08:35:03</td>\n      <td>1283.00</td>\n      <td>...</td>\n      <td>3</td>\n      <td>9.655000</td>\n      <td>40.090000</td>\n      <td>13.023867</td>\n      <td>18.200000</td>\n      <td>17.249855</td>\n      <td>12.007500</td>\n      <td>58.000000</td>\n      <td>64.000000</td>\n      <td>12.160100</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>1000014025</td>\n      <td>Monarch Espresso Bar</td>\n      <td>Restaurants</td>\n      <td>Food</td>\n      <td>USD</td>\n      <td>2016-04-01</td>\n      <td>50000.0</td>\n      <td>2016-02-26 13:38:27</td>\n      <td>52375.00</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1.313333</td>\n      <td>90.990000</td>\n      <td>3.129100</td>\n      <td>1.200000</td>\n      <td>9.615875</td>\n      <td>8.330000</td>\n      <td>69.666667</td>\n      <td>129.000000</td>\n      <td>6.093267</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>6</td>\n      <td>1000023410</td>\n      <td>Support Solar Roasted Coffee &amp; Green Energy!  ...</td>\n      <td>Food</td>\n      <td>Food</td>\n      <td>USD</td>\n      <td>2014-12-21</td>\n      <td>1000.0</td>\n      <td>2014-12-01 18:30:44</td>\n      <td>1205.00</td>\n      <td>...</td>\n      <td>2</td>\n      <td>14.432143</td>\n      <td>-2.174643</td>\n      <td>8.841846</td>\n      <td>12.828571</td>\n      <td>17.744623</td>\n      <td>13.962857</td>\n      <td>46.357143</td>\n      <td>103.285714</td>\n      <td>10.330200</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7</td>\n      <td>1000030581</td>\n      <td>Chaser Strips. Our Strips make Shots their B*tch!</td>\n      <td>Drinks</td>\n      <td>Food</td>\n      <td>USD</td>\n      <td>2016-03-17</td>\n      <td>25000.0</td>\n      <td>2016-02-01 20:05:12</td>\n      <td>453.00</td>\n      <td>...</td>\n      <td>0</td>\n      <td>-0.755000</td>\n      <td>107.600000</td>\n      <td>3.129100</td>\n      <td>1.600000</td>\n      <td>6.201631</td>\n      <td>4.120000</td>\n      <td>4.000000</td>\n      <td>114.000000</td>\n      <td>-3.067450</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>8</td>\n      <td>1000034518</td>\n      <td>SPIN - Premium Retractable In-Ear Headphones w...</td>\n      <td>Product Design</td>\n      <td>Design</td>\n      <td>USD</td>\n      <td>2014-05-29</td>\n      <td>125000.0</td>\n      <td>2014-04-24 18:14:43</td>\n      <td>8233.00</td>\n      <td>...</td>\n      <td>1</td>\n      <td>3.670000</td>\n      <td>75.875000</td>\n      <td>7.168622</td>\n      <td>6.600000</td>\n      <td>9.141557</td>\n      <td>6.475000</td>\n      <td>41.500000</td>\n      <td>109.000000</td>\n      <td>5.032550</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>9</td>\n      <td>100004195</td>\n      <td>STUDIO IN THE SKY - A Documentary Feature Film...</td>\n      <td>Documentary</td>\n      <td>Film &amp; Video</td>\n      <td>USD</td>\n      <td>2014-08-10</td>\n      <td>65000.0</td>\n      <td>2014-07-11 21:55:48</td>\n      <td>6240.57</td>\n      <td>...</td>\n      <td>1</td>\n      <td>7.586667</td>\n      <td>56.700000</td>\n      <td>8.841846</td>\n      <td>8.044444</td>\n      <td>10.310975</td>\n      <td>6.620000</td>\n      <td>42.333333</td>\n      <td>72.333333</td>\n      <td>5.286467</td>\n    </tr>\n  </tbody>\n</table>\n<p>10 rows × 33 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "import pandas as pd\n",
    "ks = pd.read_csv('./input/ks-projects-201801.csv',\n",
    "                 parse_dates=['deadline', 'launched'])\n",
    "ks.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Index(['Unnamed: 0', 'ID', 'name', 'category', 'main_category', 'currency',\n       'deadline', 'goal', 'launched', 'pledged', 'state', 'backers',\n       'country', 'usd pledged', 'usd_pledged_real', 'usd_goal_real',\n       'n_words', 'n_sents', 'n_chars', 'n_syllables', 'n_unique_words',\n       'n_long_words', 'n_monosyllable_words', 'n_polysyllable_words',\n       'flesch_kincaid_grade_level', 'flesch_reading_ease', 'smog_index',\n       'gunning_fog_index', 'coleman_liau_index',\n       'automated_readability_index', 'lix', 'gulpease_index',\n       'wiener_sachtextformel'],\n      dtype='object')"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "ks.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Preparing target column</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array(['failed', 'canceled', 'successful', 'live', 'undefined',\n       'suspended'], dtype=object)"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "pd.unique(ks.state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have six states, how many records of each?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "state\ncanceled       38779\nfailed        197719\nlive            2799\nsuccessful    133956\nsuspended       1846\nundefined       3562\nName: ID, dtype: int64"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "ks.groupby('state')['ID'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data cleaning isn't the current focus, so we'll simplify this example by:\n",
    "\n",
    "Dropping projects that are \"live\"\n",
    "Counting \"successful\" states as outcome = 1\n",
    "Combining every other state as outcome = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop live projects\n",
    "ks = ks.query('state != \"live\"')\n",
    "\n",
    "# Add outcome column, \"successful\" == 1, others are 0\n",
    "ks = ks.assign(outcome=(ks['state'] == 'successful').astype(int)) #True = 1, False = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Converting timestamps</b><br>\n",
    "I convert the launched feature into categorical features we can use in a model. Since I loaded in the columns as timestamp data, I access date and time values through the .dt attribute on the timestamp column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEE: https://www.geeksforgeeks.org/python-working-with-date-and-time-using-pandas/\n",
    "ks = ks.assign(hour=ks.launched.dt.hour,\n",
    "               day=ks.launched.dt.day,\n",
    "               month=ks.launched.dt.month,\n",
    "               year=ks.launched.dt.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   Unnamed: 0          ID                                               name  \\\n0           0  1000002330                    The Songs of Adelaide & Abullah   \n1           1  1000003930      Greeting From Earth: ZGAC Arts Capsule For ET   \n2           2  1000004038                                     Where is Hank?   \n3           3  1000007540  ToshiCapital Rekordz Needs Help to Complete Album   \n4           4  1000011046  Community Film Project: The Art of Neighborhoo...   \n\n         category main_category currency   deadline     goal  \\\n0          Poetry    Publishing      GBP 2015-10-09   1000.0   \n1  Narrative Film  Film & Video      USD 2017-11-01  30000.0   \n2  Narrative Film  Film & Video      USD 2013-02-26  45000.0   \n3           Music         Music      USD 2012-04-16   5000.0   \n4    Film & Video  Film & Video      USD 2015-08-29  19500.0   \n\n             launched  pledged  ... coleman_liau_index  \\\n0 2015-08-11 12:12:28      0.0  ...           7.680995   \n1 2017-09-02 04:43:57   2421.0  ...           3.996687   \n2 2013-01-12 00:20:50    220.0  ...          -4.103777   \n3 2012-03-17 03:24:11      1.0  ...          16.091526   \n4 2015-07-04 08:35:03   1283.0  ...          17.249855   \n\n   automated_readability_index        lix  gulpease_index  \\\n0                     4.620000  45.000000       99.000000   \n1                     2.353750  29.000000      117.750000   \n2                    -2.660000   3.000000      152.333333   \n3                    11.002857  49.857143       70.428571   \n4                    12.007500  58.000000       64.000000   \n\n   wiener_sachtextformel  outcome  hour  day  month  year  \n0               7.057000        0    12   11      8  2015  \n1               0.583800        0     4    2      9  2017  \n2              -3.643400        0     0   12      1  2013  \n3               7.216829        0     3   17      3  2012  \n4              12.160100        0     8    4      7  2015  \n\n[5 rows x 38 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>ID</th>\n      <th>name</th>\n      <th>category</th>\n      <th>main_category</th>\n      <th>currency</th>\n      <th>deadline</th>\n      <th>goal</th>\n      <th>launched</th>\n      <th>pledged</th>\n      <th>...</th>\n      <th>coleman_liau_index</th>\n      <th>automated_readability_index</th>\n      <th>lix</th>\n      <th>gulpease_index</th>\n      <th>wiener_sachtextformel</th>\n      <th>outcome</th>\n      <th>hour</th>\n      <th>day</th>\n      <th>month</th>\n      <th>year</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1000002330</td>\n      <td>The Songs of Adelaide &amp; Abullah</td>\n      <td>Poetry</td>\n      <td>Publishing</td>\n      <td>GBP</td>\n      <td>2015-10-09</td>\n      <td>1000.0</td>\n      <td>2015-08-11 12:12:28</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>7.680995</td>\n      <td>4.620000</td>\n      <td>45.000000</td>\n      <td>99.000000</td>\n      <td>7.057000</td>\n      <td>0</td>\n      <td>12</td>\n      <td>11</td>\n      <td>8</td>\n      <td>2015</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1000003930</td>\n      <td>Greeting From Earth: ZGAC Arts Capsule For ET</td>\n      <td>Narrative Film</td>\n      <td>Film &amp; Video</td>\n      <td>USD</td>\n      <td>2017-11-01</td>\n      <td>30000.0</td>\n      <td>2017-09-02 04:43:57</td>\n      <td>2421.0</td>\n      <td>...</td>\n      <td>3.996687</td>\n      <td>2.353750</td>\n      <td>29.000000</td>\n      <td>117.750000</td>\n      <td>0.583800</td>\n      <td>0</td>\n      <td>4</td>\n      <td>2</td>\n      <td>9</td>\n      <td>2017</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>1000004038</td>\n      <td>Where is Hank?</td>\n      <td>Narrative Film</td>\n      <td>Film &amp; Video</td>\n      <td>USD</td>\n      <td>2013-02-26</td>\n      <td>45000.0</td>\n      <td>2013-01-12 00:20:50</td>\n      <td>220.0</td>\n      <td>...</td>\n      <td>-4.103777</td>\n      <td>-2.660000</td>\n      <td>3.000000</td>\n      <td>152.333333</td>\n      <td>-3.643400</td>\n      <td>0</td>\n      <td>0</td>\n      <td>12</td>\n      <td>1</td>\n      <td>2013</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>1000007540</td>\n      <td>ToshiCapital Rekordz Needs Help to Complete Album</td>\n      <td>Music</td>\n      <td>Music</td>\n      <td>USD</td>\n      <td>2012-04-16</td>\n      <td>5000.0</td>\n      <td>2012-03-17 03:24:11</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>16.091526</td>\n      <td>11.002857</td>\n      <td>49.857143</td>\n      <td>70.428571</td>\n      <td>7.216829</td>\n      <td>0</td>\n      <td>3</td>\n      <td>17</td>\n      <td>3</td>\n      <td>2012</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>1000011046</td>\n      <td>Community Film Project: The Art of Neighborhoo...</td>\n      <td>Film &amp; Video</td>\n      <td>Film &amp; Video</td>\n      <td>USD</td>\n      <td>2015-08-29</td>\n      <td>19500.0</td>\n      <td>2015-07-04 08:35:03</td>\n      <td>1283.0</td>\n      <td>...</td>\n      <td>17.249855</td>\n      <td>12.007500</td>\n      <td>58.000000</td>\n      <td>64.000000</td>\n      <td>12.160100</td>\n      <td>0</td>\n      <td>8</td>\n      <td>4</td>\n      <td>7</td>\n      <td>2015</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 38 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "ks.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Prepping categorical variables</b><br>\n",
    "Now for the categorical variables -- category, currency, and country -- I'll need to convert them into integers so our model can use the data. For this I'll use scikit-learn's LabelEncoder. This assigns an integer to each value of the categorical feature and replaces those values with the integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   category  currency  country\n0       108         5        9\n1        93        13       22\n2        93        13       22\n3        90        13       22\n4        55        13       22\n5       123        13       22\n6        58        13       22\n7        41        13       22\n8       113        13       22\n9        39        13       22",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>category</th>\n      <th>currency</th>\n      <th>country</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>108</td>\n      <td>5</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>93</td>\n      <td>13</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>93</td>\n      <td>13</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>90</td>\n      <td>13</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>55</td>\n      <td>13</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>123</td>\n      <td>13</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>58</td>\n      <td>13</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>41</td>\n      <td>13</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>113</td>\n      <td>13</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>39</td>\n      <td>13</td>\n      <td>22</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "cat_features = ['category', 'currency', 'country']\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# Apply the label encoder to each column\n",
    "encoded = ks[cat_features].apply(encoder.fit_transform)\n",
    "encoded.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll collect all the features we'll use in a new dataframe and use that to train a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "       goal  hour  day  month  year  outcome  category  currency  country\n0    1000.0    12   11      8  2015        0       108         5        9\n1   30000.0     4    2      9  2017        0        93        13       22\n2   45000.0     0   12      1  2013        0        93        13       22\n3    5000.0     3   17      3  2012        0        90        13       22\n4   19500.0     8    4      7  2015        0        55        13       22\n5   50000.0    13   26      2  2016        1       123        13       22\n6    1000.0    18    1     12  2014        1        58        13       22\n7   25000.0    20    1      2  2016        0        41        13       22\n8  125000.0    18   24      4  2014        0       113        13       22\n9   65000.0    21   11      7  2014        0        39        13       22",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>goal</th>\n      <th>hour</th>\n      <th>day</th>\n      <th>month</th>\n      <th>year</th>\n      <th>outcome</th>\n      <th>category</th>\n      <th>currency</th>\n      <th>country</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1000.0</td>\n      <td>12</td>\n      <td>11</td>\n      <td>8</td>\n      <td>2015</td>\n      <td>0</td>\n      <td>108</td>\n      <td>5</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>30000.0</td>\n      <td>4</td>\n      <td>2</td>\n      <td>9</td>\n      <td>2017</td>\n      <td>0</td>\n      <td>93</td>\n      <td>13</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>45000.0</td>\n      <td>0</td>\n      <td>12</td>\n      <td>1</td>\n      <td>2013</td>\n      <td>0</td>\n      <td>93</td>\n      <td>13</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5000.0</td>\n      <td>3</td>\n      <td>17</td>\n      <td>3</td>\n      <td>2012</td>\n      <td>0</td>\n      <td>90</td>\n      <td>13</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>19500.0</td>\n      <td>8</td>\n      <td>4</td>\n      <td>7</td>\n      <td>2015</td>\n      <td>0</td>\n      <td>55</td>\n      <td>13</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>50000.0</td>\n      <td>13</td>\n      <td>26</td>\n      <td>2</td>\n      <td>2016</td>\n      <td>1</td>\n      <td>123</td>\n      <td>13</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1000.0</td>\n      <td>18</td>\n      <td>1</td>\n      <td>12</td>\n      <td>2014</td>\n      <td>1</td>\n      <td>58</td>\n      <td>13</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>25000.0</td>\n      <td>20</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2016</td>\n      <td>0</td>\n      <td>41</td>\n      <td>13</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>125000.0</td>\n      <td>18</td>\n      <td>24</td>\n      <td>4</td>\n      <td>2014</td>\n      <td>0</td>\n      <td>113</td>\n      <td>13</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>65000.0</td>\n      <td>21</td>\n      <td>11</td>\n      <td>7</td>\n      <td>2014</td>\n      <td>0</td>\n      <td>39</td>\n      <td>13</td>\n      <td>22</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "# Since ks and encoded have the same index and I can easily join them\n",
    "data = ks[['goal', 'hour', 'day', 'month', 'year', 'outcome']].join(encoded)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Creating training, validation, and test splits</b><br>\n",
    "We need to create data sets for training, validation, and testing. We'll use a fairly simple approach and split the data using slices. We'll use 10% of the data as a validation set, 10% for testing, and the other 80% for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/34329617/how-colon-works-in-python-pandas\n",
    "#https://stackoverflow.com/questions/509211/understanding-slice-notation\n",
    "valid_fraction = 0.1\n",
    "valid_size = int(len(data) * valid_fraction)\n",
    "\n",
    "train = data[:-2 * valid_size] #data from beginning to -0.2 i.e., everything to last 20% of data\n",
    "valid = data[-2 * valid_size:-valid_size] #last 20% to last 10%\n",
    "test = data[-valid_size:] #last 10% to end of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general you want to be careful that each data set has the same proportion of target classes. I'll print out the fraction of successful outcomes for each of our datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Outcome fraction = 0.3570\nOutcome fraction = 0.3539\nOutcome fraction = 0.3542\n"
    }
   ],
   "source": [
    "for each in [train, valid, test]:\n",
    "    print(f\"Outcome fraction = {each.outcome.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks good, each set is around 35% true outcomes likely because the data was well randomized beforehand. A good way to do this automatically is with sklearn.model_selection.StratifiedShuffleSplit but I don't need to use it here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Training a LightGBM model</b><br>\n",
    "For this course we'll be using a LightGBM model. This is a tree-based model that typically provides the best performance, even compared to XGBoost. It's also relatively fast to train. We won't do hyperparameter optimization because that isn't the goal of this course. So, our models won't be the absolute best performance you can get. But you'll still see model performance improve as we do feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "feature_cols = train.columns.drop('outcome')\n",
    "\n",
    "dtrain = lgb.Dataset(train[feature_cols], label=train['outcome'])\n",
    "dvalid = lgb.Dataset(valid[feature_cols], label=valid['outcome'])\n",
    "\n",
    "param = {'num_leaves': 64, 'objective': 'binary'}\n",
    "param['metric'] = 'auc'\n",
    "num_round = 1000\n",
    "bst = lgb.train(param, dtrain, num_round, valid_sets=[dvalid], early_stopping_rounds=10, verbose_eval=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Making predictions & evaluating the model</b><br>\n",
    "Finally, let's make predictions on the test set with the model and see how well it performs. An important thing to remember is that you can overfit to the validation data. This is why we need a test set that the model never sees until the final evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Test AUC score: 0.747615303004287\n"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "ypred = bst.predict(test[feature_cols])\n",
    "score = metrics.roc_auc_score(test['outcome'], ypred)\n",
    "\n",
    "print(f\"Test AUC score: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bitworkconda23fa24f4f02a4d25ae6ccbff27cf086c",
   "display_name": "Python 3.7.7 64-bit ('work': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}